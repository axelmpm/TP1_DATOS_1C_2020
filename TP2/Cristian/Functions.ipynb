{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_output(ids, prediction,name):\n",
    "    df_ids = ids\n",
    "    result = df_ids.to_frame()\n",
    "    result[\"target\"] = prediction\n",
    "    result.to_csv('../predictions/'+name, index=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    score = model.score(test_features,test_labels)\n",
    "    print('Entrenamiento: {:0.4f}%'.format(model.score(train_features, train_labels)*100))\n",
    "    print('Testeo: {:0.4f}%.'.format(score*100))\n",
    "    print (\"F1 Score: \", f1_score(test_labels, predictions))\n",
    "    print (\"F1 Score default: \", f1_score(test_labels, predictions))\n",
    "   # print (\"F1 Score: \", f1_score(test_labels, test_features[\"sentimiento\"],average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(list_, train,test, target):\n",
    "    cosa = 0\n",
    "    if (target == 1):\n",
    "        cosa =1\n",
    "    test[\"1-gram-\"+str(cosa)]= 0\n",
    "    test[\"2-gram-\"+str(cosa)]= 0\n",
    "    test[\"3-gram-\"+str(cosa)]= 0\n",
    "    train[\"1-gram-\"+str(cosa)]= 0\n",
    "    train[\"2-gram-\"+str(cosa)]= 0\n",
    "    train[\"3-gram-\"+str(cosa)]= 0\n",
    "\n",
    "    for x in list_:\n",
    "        #print (x)\n",
    "        fin =len(x)\n",
    "        n_grams = 0\n",
    "        while (n_grams < fin):\n",
    "            grams = 0\n",
    "            w =\"\"\n",
    "            \n",
    "            if ((fin - n_grams) >0):\n",
    "                if (grams != 0):\n",
    "                    w+=\" \"\n",
    "                w+=str(x[n_grams + grams])\n",
    "                grams+=1\n",
    "                test[str(grams)+\"-gram-\"+str(cosa)] = test[str(grams)+\"-gram-\"+str(cosa)] + test['text'].apply(lambda x: 1 if w in x else 0 )\n",
    "                train[str(grams)+\"-gram-\"+str(cosa)] = train[str(grams)+\"-gram-\"+str(cosa)] + train['text'].apply(lambda x: 1 if w in x else 0 )\n",
    "               # print (w)\n",
    "                \n",
    "            if ((fin - n_grams) > 1):\n",
    "                w+=\" \"\n",
    "                w+=str(x[n_grams + grams])\n",
    "                grams+=1\n",
    "                test[str(grams)+\"-gram-\"+str(cosa)] = test[str(grams)+\"-gram-\"+str(cosa)] + test['text'].apply(lambda x: 1 if w in x else 0 )\n",
    "                train[str(grams)+\"-gram-\"+str(cosa)] = train[str(grams)+\"-gram-\"+str(cosa)] + train['text'].apply(lambda x: 1 if w in x else 0 )\n",
    "               # print (w)\n",
    "                \n",
    "            if ((fin - n_grams) > 2):\n",
    "                w+=\" \"\n",
    "                w+=str(x[n_grams + grams])\n",
    "                grams+=1\n",
    "                test[str(grams)+\"-gram-\"+str(cosa)] = test[str(grams)+\"-gram-\"+str(cosa)] + test['text'].apply(lambda x: 1 if w in x else 0 )\n",
    "                train[str(grams)+\"-gram-\"+str(cosa)] = train[str(grams)+\"-gram-\"+str(cosa)] + train['text'].apply(lambda x: 1 if w in x else 0 )\n",
    "               # print (w)\n",
    "               # print (\" \")\n",
    "            n_grams+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(df_train, df_test):\n",
    "    df_test['len']=df_test.text.map(lambda x: len(str(x)))#/280)\n",
    "    df_test[\"word_count\"] = df_test.text.map(lambda x: len(x.split(\" \")))\n",
    "    #df_test['importance']= df_test.text.map(lambda x: calculateTweetImportance(x))\n",
    "    \n",
    "    df_train['len']=df_train.text.map(lambda x: len(x))#/280)\n",
    "    df_train[\"word_count\"] = df_train.text.map(lambda x: len(x.split(\" \")))\n",
    "   \n",
    "    #df_train['importance']= df_train.text.map(lambda x: calculateTweetImportance(x))\n",
    "\n",
    "    # unique_word_count\n",
    "    df_train['unique_word_count'] = df_train['text'].apply(lambda x: len(set(str(x).split())))\n",
    "    df_test['unique_word_count'] = df_test['text'].apply(lambda x: len(set(str(x).split())))\n",
    "    \n",
    "    #df_train['unique_word_count'] = df_train['unique_word_count']/df_train[\"word_count\"]\n",
    "    #df_train[\"word_count\"] = df_train[\"word_count\"]/df_train[\"word_count\"].max()\n",
    "    \n",
    "    #df_test['unique_word_count'] = df_test['unique_word_count']/df_test[\"word_count\"]\n",
    "    #df_test[\"word_count\"] = df_test[\"word_count\"]/df_test[\"word_count\"].max()\n",
    "    \n",
    "    # url_count\n",
    "    df_train['url_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "    df_test['url_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "    \n",
    "    df_train[\"url_count\"] = df_train[\"url_count\"] > 0\n",
    "    df_test[\"url_count\"] = df_test[\"url_count\"] > 0\n",
    "\n",
    "    # mean_word_length\n",
    "    df_train['mean_word_length'] = df_train['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "    df_test['mean_word_length'] = df_test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "    # punctuation_count\n",
    "    #df_train['punctuation_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "    #df_test['punctuation_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "    #df_train[\"punctuation_count\"] = df_train[\"punctuation_count\"] > 0\n",
    "    #df_test[\"punctuation_count\"] = df_test[\"punctuation_count\"] > 0\n",
    "    # hashtag_count\n",
    "    df_train['hashtag_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "    df_test['hashtag_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "    #mention_count\n",
    "    df_train['mention_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "    df_test['mention_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '@'])) \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(train, to_predict):\n",
    "    key_ =list(train[\"keyword\"].unique())\n",
    "    train['Kindex']=train.keyword.map(lambda x:f'{( key_.index(x)):08b}')\n",
    "    to_predict['Kindex']=to_predict.keyword.map(lambda x:f'{( key_.index(x)):08b}')\n",
    "\n",
    "    bits=0\n",
    "    Found=False\n",
    "    while (not Found):\n",
    "        x = pow(2, bits)\n",
    "        if (len(key_) > x ):\n",
    "            bits+=1\n",
    "        else:\n",
    "            Found= True\n",
    "    bits\n",
    "\n",
    "    for x in range(8):\n",
    "        feat = 'key_bit'+str(x)\n",
    "        train[feat] = 0\n",
    "        to_predict[feat]=0\n",
    "\n",
    "    for x in range(bits):\n",
    "        train['key_bit'+str(x)]=train.Kindex.map(lambda y: int(y[x]))\n",
    "        to_predict['key_bit'+str(x)]=to_predict.Kindex.map(lambda y: int(y[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_in_text_2(df):\n",
    "    \"\"\"\n",
    "    RECIBE: un df\n",
    "    DEVUELVE: el mismo df con una columna que indica si la keyword esta en el tweet.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['contains_keyword'] = 0\n",
    "    cant_filas = len(df.index)\n",
    "    for y in range(cant_filas):\n",
    "        df['contains_keyword'][y:]= str(df.iloc[y][0]).lower() in str(df.iloc[y][17]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_in_text(df):\n",
    "    \"\"\"\n",
    "    RECIBE: un df\n",
    "    DEVUELVE: el mismo df con una columna que indica si la keyword esta en el tweet.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['contains_keyword'] = 0\n",
    "    cant_filas = len(df.index)\n",
    "    for y in range(cant_filas):\n",
    "        df['contains_keyword'][y:]= str(df.iloc[y][1]).lower() in str(df.iloc[y][3]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_words(train, to_predict):  \n",
    "    archivo = open(\"NW.txt\", \"r\")\n",
    "    for linea in archivo.readlines():\n",
    "        train[\"Tiene_\"+str(linea[:-1])] = train['text'].apply(lambda x: str(linea[:-1]) in str(x))\n",
    "        to_predict[\"Tiene_\"+str(linea[:-1])] = to_predict['text'].apply(lambda x: str(linea[:-1]) in str(x))\n",
    "    archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_words(train,to_predict,listaPalabras,dict_0,dict_1):\n",
    "    to_predict[\"Puntaje_ser_1\"]= 0\n",
    "    to_predict[\"Puntaje_ser_0\"]= 0\n",
    "    train[\"Puntaje_ser_1\"]= 0\n",
    "    train[\"Puntaje_ser_0\"]= 0\n",
    "    cant_1=0\n",
    "    cant_0=0\n",
    "    for palabra in listaPalabras:\n",
    "        if palabra in dict_0:\n",
    "            cant_0 = dict_0[palabra]\n",
    "        if palabra in dict_1:\n",
    "            cant_1 = dict_1[palabra]\n",
    "        prob_1 = cant_0 /(cant_1 +cant_0)\n",
    "        prob_0 = cant_1 /(cant_1 +cant_0)\n",
    "        to_predict[\"Prob_0_x\"+str(palabra)] = to_predict.text.map(lambda x: prob_0 if (str(palabra) in str(x)) else 0 )\n",
    "        to_predict[\"Puntaje_ser_0\"]= to_predict[\"Puntaje_ser_0\"] +  to_predict[\"Prob_0_x\"+str(palabra)]\\\n",
    "        .map(lambda x: x )\n",
    "        to_predict.drop(columns=[\"Prob_0_x\"+str(palabra)], axis=1,inplace = True)\n",
    "        \n",
    "        to_predict[\"Prob_1_x\"+str(palabra)] = to_predict.text.map(lambda x: prob_1 if (str(palabra) in str(x)) else 0 )\n",
    "        to_predict[\"Puntaje_ser_1\"]= to_predict[\"Puntaje_ser_1\"] +  to_predict[\"Prob_1_x\"+str(palabra)]\\\n",
    "        .map(lambda x: x )\n",
    "        to_predict.drop(columns=[\"Prob_1_x\"+str(palabra)], axis=1,inplace = True)\n",
    "        \n",
    "        train[\"Prob_0_x\"+str(palabra)] = train.text.map(lambda x: prob_0 if (str(palabra) in str(x)) else 0 )\n",
    "        train[\"Puntaje_ser_0\"]= train[\"Puntaje_ser_0\"] +  train[\"Prob_0_x\"+str(palabra)]\\\n",
    "        .map(lambda x: x )\n",
    "        train.drop(columns=[\"Prob_0_x\"+str(palabra)], axis=1,inplace = True)\n",
    "        \n",
    "        train[\"Prob_1_x\"+str(palabra)] = train.text.map(lambda x: prob_1 if (str(palabra) in str(x)) else 0 )\n",
    "        train[\"Puntaje_ser_1\"]= train[\"Puntaje_ser_1\"] +  train[\"Prob_1_x\"+str(palabra)]\\\n",
    "        .map(lambda x: x ) \n",
    "        train.drop(columns=[\"Prob_1_x\"+str(palabra)], axis=1,inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation, html tags, symbols, numbers, etc.\n",
    "#has_words(train, to_predict)\n",
    "\n",
    "def remove_noise(text):\n",
    "    # Dealing with Punctuation\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def remove(train, to_predict):\n",
    "    #Calling remove_noise function in order to remove noise\n",
    "    train['text'] = train['text'].apply(lambda x: remove_noise(x))\n",
    "    train[\"text\"]=(train.text.map(lambda x: (x.lower())))\n",
    "    to_predict['text'] = to_predict['text'].apply(lambda x: remove_noise(x))\n",
    "    to_predict[\"text\"]=(to_predict.text.map(lambda x: (x.lower())))\n",
    "    \n",
    "    from nlppreprocess import NLP\n",
    "\n",
    "    nlp = NLP()\n",
    "\n",
    "    train['text'] = train['text'].apply(nlp.process)\n",
    "    to_predict['text'] = to_predict['text'].apply(nlp.process)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Has(df):\n",
    "    #Posibles 1\n",
    "    df[\"Tiene_key_impor\"] = (df[\"keyword\"] == \"wreckage\") | (df[\"keyword\"] == \"debris\") | (df[\"keyword\"] == \"derailment\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Tiene_key_impor\"].map(lambda x: 1  if (x == True) else 0)\n",
    "    df[\"Tiene_key_impor\"] = df[\"Tiene_key_impor\"].map(lambda x: 1 if (x == True) else 0)\n",
    "\n",
    "    df[\"Es_outbreak\"] = (df[\"keyword\"] == \"outbreak\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_outbreak\"].map(lambda x: 0.975  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_outbreak\"].map(lambda x: 0.025  if (x == False) else 0)\n",
    "    df[\"Es_outbreak\"] = df[\"keyword\"].map(lambda x: 0.975 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_outbreak\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_oil_split\"] = (df[\"keyword\"] == \"oil split\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_oil_split\"].map(lambda x: 0.973  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_oil_split\"].map(lambda x: 0.027  if (x == False) else 0)\n",
    "    df[\"Es_oil_split\"] = df[\"keyword\"].map(lambda x: 0.973 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_oil_split\"], axis=1,inplace = True)\n",
    "    \n",
    "    df[\"Es_typhoon\"] = (df[\"keyword\"] == \"typhoon\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_typhoon\"].map(lambda x: 0.973  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_typhoon\"].map(lambda x: 0.027  if (x == False) else 0)\n",
    "    df[\"Es_typhoon\"] = df[\"keyword\"].map(lambda x: 0.973 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_typhoon\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_suicide_bombing\"] = (df[\"keyword\"] == \"suicide bombing\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_suicide_bombing\"].map(lambda x: 0.969  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_suicide_bombing\"].map(lambda x: 0.031  if (x == False) else 0)\n",
    "    df[\"Es_suicide_bombing\"] = df[\"keyword\"].map(lambda x: 0.969 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_suicide_bombing\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_suicide_bomber\"] = (df[\"keyword\"] == \"suicide bomber\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_suicide_bomber\"].map(lambda x: 0.967  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_suicide_bomber\"].map(lambda x: 0.033  if (x == False) else 0)\n",
    "    df[\"Es_suicide_bomber\"] = df[\"keyword\"].map(lambda x: 0.967 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_suicide_bomber\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_bombing\"] = (df[\"keyword\"] == \"bombing\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_bombing\"].map(lambda x: 0.931  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_bombing\"].map(lambda x: 0.069  if (x == False) else 0)\n",
    "    df[\"Es_bombing\"] = df[\"keyword\"].map(lambda x: 0.931 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_bombing\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_suicide_bomb\"] = (df[\"keyword\"] == \"suicide bomb\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_suicide_bomb\"].map(lambda x: 0.914  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_suicide_bomb\"].map(lambda x: 0.086  if (x == False) else 0)\n",
    "    df[\"Es_suicide_bomb\"] = df[\"keyword\"].map(lambda x: 0.914 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_suicide_bomb\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_rescuers\"] = (df[\"keyword\"] == \"rescuers\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_rescuers\"].map(lambda x: 0.914  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_rescuers\"].map(lambda x: 0.086  if (x == False) else 0)\n",
    "    df[\"Es_rescuers\"] = df[\"keyword\"].map(lambda x: 0.914 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_rescuers\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_nuclear_disaster\"] = (df[\"keyword\"] == \"nuclear disaster\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_nuclear_disaster\"].map(lambda x: 0.911  if (x == True) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_nuclear_disaster\"].map(lambda x: 0.089  if (x == False) else 0)\n",
    "    df[\"Es_nuclear_disaster\"] = df[\"keyword\"].map(lambda x: 0.911 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_nuclear_disaster\"], axis=1,inplace = True)\n",
    "\n",
    "\n",
    "    #Posibles 0\n",
    "    df[\"Tiene_key_no_impor\"] = (df[\"keyword\"] == \"wreckage\") | (df[\"keyword\"] == \"debris\") | (df[\"keyword\"] == \"derailment\") \n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Tiene_key_no_impor\"].map(lambda x: 1  if (x == True) else 0)\n",
    "    df[\"Tiene_key_no_impor\"] =df[\"keyword\"].map(lambda x: 1 if (x == True) else 0)\n",
    "\n",
    "    df[\"Es_body_bags\"] = (df[\"keyword\"] == \"body bags\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_body_bags\"].map(lambda x: 0.025  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_body_bags\"].map(lambda x: 0.975  if (x == True) else 0)\n",
    "    df[\"Es_body_bags\"] = df[\"keyword\"].map(lambda x: 0.975 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_body_bags\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_ruin\"] = (df[\"keyword\"] == \"ruin\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_ruin\"].map(lambda x: 0.027  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_ruin\"].map(lambda x: 0.973  if (x == True) else 0)\n",
    "    df[\"Es_ruin\"] = df[\"keyword\"].map(lambda x: 0.973 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_ruin\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_blazing\"] = (df[\"keyword\"] == \"blazing\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_blazing\"].map(lambda x: 0.030  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_blazing\"].map(lambda x: 0.970  if (x == True) else 0)\n",
    "    df[\"Es_blazing\"] = df[\"keyword\"].map(lambda x: 0.970 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_blazing\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_electrocute\"] = (df[\"keyword\"] == \"electrocute\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_electrocute\"].map(lambda x: 0.032  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_electrocute\"].map(lambda x: 0.968  if (x == True) else 0)\n",
    "    df[\"Es_electrocute\"] = df[\"keyword\"].map(lambda x: 0.968 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_electrocute\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_traumatised\"] = (df[\"keyword\"] == \"traumatised\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_traumatised\"].map(lambda x: 0.058  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_traumatised\"].map(lambda x: 0.942  if (x == True) else 0)\n",
    "    df[\"Es_traumatised\"] = df[\"keyword\"].map(lambda x: 0.942 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_traumatised\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_blew_up\"] = (df[\"keyword\"] == \"blew up\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_blew_up\"].map(lambda x: 0.061  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_blew_up\"].map(lambda x: 0.939  if (x == True) else 0)\n",
    "    df[\"Es_blew_up\"] = df[\"keyword\"].map(lambda x: 0.939 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_blew_up\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_panicking\"] = (df[\"keyword\"] == \"panicking\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_panicking\"].map(lambda x: 0.061  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_panicking\"].map(lambda x: 0.939  if (x == True) else 0)\n",
    "    df[\"Es_panicking\"] = df[\"keyword\"].map(lambda x: 0.939 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_panicking\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_body_bag\"] = (df[\"keyword\"] == \"body bag\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_body_bag\"].map(lambda x: 0.030  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_body_bag\"].map(lambda x: 0.970  if (x == True) else 0)\n",
    "    df[\"Es_body_bag\"] = df[\"keyword\"].map(lambda x: 0.970 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_body_bag\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_screaming\"] = (df[\"keyword\"] == \"screaming\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_screaming\"].map(lambda x: 0.055  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_screaming\"].map(lambda x: 0.945  if (x == True) else 0)\n",
    "    df[\"Es_screaming\"] = df[\"keyword\"].map(lambda x: 0.945 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_screaming\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_blight\"] = (df[\"keyword\"] == \"blight\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_blight\"].map(lambda x: 0.063  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_blight\"].map(lambda x: 0.937  if (x == True) else 0)\n",
    "    df[\"Es_blight\"] = df[\"keyword\"].map(lambda x: 0.937 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_blight\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_wrecked\"] = (df[\"keyword\"] == \"wrecked\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_wrecked\"].map(lambda x: 0.077  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_wrecked\"].map(lambda x: 0.923  if (x == True) else 0)\n",
    "    df[\"Es_wrecked\"] = df[\"keyword\"].map(lambda x: 0.923 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_wrecked\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_explode\"] = (df[\"keyword\"] == \"explode\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_explode\"].map(lambda x: 0.089  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_explode\"].map(lambda x: 0.921  if (x == False) else 0)\n",
    "    df[\"Es_explode\"] = df[\"keyword\"].map(lambda x: 0.921 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_explode\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_epicentre\"] = (df[\"keyword\"] == \"epicentre\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_epicentre\"].map(lambda x: 0.083  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_epicentre\"].map(lambda x: 0.917  if (x == True) else 0)\n",
    "    df[\"Es_epicentre\"] = df[\"keyword\"].map(lambda x: 0.917 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_epicentre\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_panic\"] = (df[\"keyword\"] == \"panic\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_panic\"].map(lambda x: 0.081  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_panic\"].map(lambda x: 0.919  if (x == True) else 0)\n",
    "    df[\"Es_panic\"] = df[\"keyword\"].map(lambda x: 0.919 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_panic\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_bloody\"] = (df[\"keyword\"] == \"bloody\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_bloody\"].map(lambda x: 0.086  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_bloody\"].map(lambda x: 0.914  if (x == True) else 0)\n",
    "    df[\"Es_bloody\"] = df[\"keyword\"].map(lambda x: 0.914 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_bloody\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_drown\"] = (df[\"keyword\"] == \"drown\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_drown\"].map(lambda x: 0.094  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_drown\"].map(lambda x: 0.906  if (x == True) else 0)\n",
    "    df[\"Es_drown\"] = df[\"keyword\"].map(lambda x: 0.906 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_drown\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_stretcher\"] = (df[\"keyword\"] == \"stretcher\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_stretcher\"].map(lambda x: 0.091  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_stretcher\"].map(lambda x: 0.909  if (x == True) else 0)\n",
    "    df[\"Es_stretcher\"] = df[\"keyword\"].map(lambda x: 0.909 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_stretcher\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_collide\"] = (df[\"keyword\"] == \"collide\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_collide\"].map(lambda x: 0.089  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_collide\"].map(lambda x: 0.911  if (x == True) else 0)\n",
    "    df[\"Es_collide\"] = df[\"keyword\"].map(lambda x: 0.911 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_collide\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_smoke\"] = (df[\"keyword\"] == \"smoke\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_smoke\"].map(lambda x: 0.089  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_smoke\"].map(lambda x: 0.911  if (x == True) else 0)\n",
    "    df[\"Es_smoke\"] = df[\"keyword\"].map(lambda x: 0.911 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_smoke\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_harm\"] = (df[\"keyword\"] == \"harm\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_harm\"].map(lambda x: 0.097  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_harm\"].map(lambda x: 0.902  if (x == True) else 0)\n",
    "    df[\"Es_harm\"] = df[\"keyword\"].map(lambda x: 0.903 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_harm\"], axis=1,inplace = True)\n",
    "\n",
    "    df[\"Es_drown\"] = (df[\"keyword\"] == \"drown\") \n",
    "    df[\"Puntaje_ser_1\"]= df[\"Puntaje_ser_1\"] + df[\"Es_drown\"].map(lambda x: 0.094  if (x == False) else 0)\n",
    "    df[\"Puntaje_ser_0\"]= df[\"Puntaje_ser_0\"] + df[\"Es_drown\"].map(lambda x: 0.906  if (x == True) else 0)\n",
    "    df[\"Es_drown\"] = df[\"keyword\"].map(lambda x: 0.906 if (x == True) else 0)\n",
    "    df.drop(columns=[\"Es_drown\"], axis=1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asd(train):\n",
    "\n",
    "    unos = train[train[\"target\"]==1]\n",
    "    ceros = train[train[\"target\"]==0]\n",
    "    y = []\n",
    "    n = []\n",
    "    unos[\"sepa\"]=(unos.text.map(lambda x: (x.split())))\n",
    "    ceros[\"sepa\"] = (ceros.text.map(lambda x: (x.split())))\n",
    "    for x in unos['sepa']:\n",
    "        y.append(x)\n",
    "\n",
    "\n",
    "    for i in ceros['sepa']:\n",
    "        n.append(i)\n",
    "    return y, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresKNN(df_train, df_test):\n",
    "    df_test['len']=df_test.text.map(lambda x: len(x)/280)\n",
    "    df_test[\"word_count\"] = df_test.text.map(lambda x: len(x.split(\" \")))\n",
    "    df_test[\"word_count\"] = df_test[\"word_count\"]/df_test[\"word_count\"].max()\n",
    "    #df_test['importance']= df_test.text.map(lambda x: calculateTweetImportance(x))\n",
    "    \n",
    "    df_train['len']=df_train.text.map(lambda x: len(x)/280)\n",
    "    df_train[\"word_count\"] = df_train.text.map(lambda x: len(x.split(\" \")))\n",
    "    df_train[\"word_count\"] = df_train[\"word_count\"]/df_train[\"word_count\"].max()\n",
    "    #df_train['importance']= df_train.text.map(lambda x: calculateTweetImportance(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_best_distance(df,dist,x_train,y_train,x_test,y_test):\n",
    "    for x in dist:\n",
    "        print(x+\" --------------------------\")\n",
    "        result , k = knn_predictor(x,x_train,y_train,x_test,y_test)\n",
    "        \n",
    "        df[x] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predictor(distancia,x_train,y_train,x_test,y_test):\n",
    "    kesimos = []\n",
    "    result = []\n",
    "    for k in range(2,40):\n",
    "        print(\"con k: \", k)\n",
    "        kesimos.append(k)\n",
    "        knn = KNeighborsClassifier(n_neighbors = k, metric=distancia)\n",
    "        knn.fit(x_train, y_train)\n",
    "        res = predecir(knn,x_train,y_train,x_test,y_test)\n",
    "        result.append(res)\n",
    "    return result, kesimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(model, train_features, train_labels, test_features, test_labels):\n",
    "    score = model.score(test_features,test_labels)\n",
    "    predict = model.predict(test_features)\n",
    "    \n",
    "    print('Entrenamiento: {:0.4f}%'.format(model.score(train_features, train_labels)*100))\n",
    "    print('Testeo: {:0.4f}%.'.format(score*100))\n",
    "    \n",
    "    error1 = f1_score(test_labels, predict)\n",
    "    print('F1 score: {:0.4f}.'.format(error1))\n",
    "    print (\"   \")\n",
    "    return error1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones Reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobar(best_predict):\n",
    "    test_labels = pd.read_csv(\"../Data/perfect_submission.csv\")\n",
    "    test_labels = test_labels[\"target\"]\n",
    "    print (\"F1 Score: \", f1_score(test_labels, best_predict,average='micro'))\n",
    "    print (\"F1 Score default: \", f1_score(test_labels, best_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
