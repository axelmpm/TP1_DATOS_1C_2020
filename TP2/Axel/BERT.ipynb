{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert'...\n",
      "remote: Enumerating objects: 340, done.\u001b[K\n",
      "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
      "Receiving objects: 100% (340/340), 317.20 KiB | 805.00 KiB/s, done.\n",
      "Resolving deltas: 100% (185/185), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/google-research/bert.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['KAGGLE_USERNAME'] = 'axelmpm'\n",
    "#os.environ['KAGGLE_KEY'] = '7ec546262604be71b856d29b2597ac36'\n",
    "#!kaggle competitions download -c nlp-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formateo data con el formato que BERT espera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(' ')\n",
    "train['alpha'] = 'a'\n",
    "train.index = train.id\n",
    "train['text'] = train['keyword'] + ' ' + train['location'] + ' ' + train['text']\n",
    "train['label'] = train['target']\n",
    "train = train[['id','label','alpha','text']]\n",
    "\n",
    "test = test.fillna(' ')\n",
    "test.index = test.id\n",
    "test['text'] = test['keyword'] + ' ' + test['location'] + ' ' + test['text']\n",
    "test = test[['id','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibro la data entre los labels para evitar biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3271, 4342)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_1 = train[train['label'] == 1]\n",
    "tag_0 = train[train['label'] == 0]\n",
    "\n",
    "len(tag_1),len(tag_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5232, 2381)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Esto es para que el set de train este equilibrado entre 1 y 0 y para que el \n",
    "#set de validacion tenga solo datos nuevos que no se usaron en train \n",
    "#y que a la vez no se termine dejando ningun dato sin usar\n",
    "\n",
    "tag_1_dev_size = 0.2\n",
    "\n",
    "tag_0_dev_size = 1 - (len(tag_1) * (1 - tag_1_dev_size))/(len(tag_0))\n",
    "\n",
    "tag_1_train, tag_1_dev = train_test_split(tag_1, test_size = tag_1_dev_size)\n",
    "tag_0_train, tag_0_dev = train_test_split(tag_0, test_size = tag_0_dev_size)\n",
    "\n",
    "train = pd.concat([tag_1_train,tag_0_train])\n",
    "dev = pd.concat([tag_1_dev,tag_0_dev])\n",
    "len(train),len(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar data en formato tsv para BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/bert_data/train.tsv', sep='\\t', index=False, header=False)\n",
    "dev.to_csv('data/bert_data/dev.tsv', sep='\\t', index=False, header=False)\n",
    "test.to_csv('data/bert_data/test.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-5c4bee79568f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-5c4bee79568f>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    --data_dir=./data/\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!python bert/run_classifier.py \n",
    "--task_name=cola \n",
    "--do_train=true \n",
    "--do_eval=true \n",
    "--do_predict=true \n",
    "--data_dir=./data/ \n",
    "--vocab_file=./cased_L-12_H-768_A-12/vocab.txt \n",
    "--bert_config_file=./cased_L-12_H-768_A-12/bert_config.json \n",
    "--init_checkpoint=./cased_L-12_H-768_A-12/bert_model.ckpt \n",
    "--max_seq_length=400 \n",
    "--train_batch_size=32 \n",
    "--learning_rate=2e-5 \n",
    "--num_train_epochs=1.0 \n",
    "--output_dir=./bert_output/ \n",
    "--do_lower_case=False\n",
    "--save_checkpoints_steps=9999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencia\n",
    "\n",
    "    https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
